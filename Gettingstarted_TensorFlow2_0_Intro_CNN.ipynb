{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Gettingstarted-TensorFlow2.0-Intro-CNN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ccarpenterg/LearningTensorFlow2.0/blob/master/Gettingstarted_TensorFlow2_0_Intro_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3Bkv9vJHsYg",
        "colab_type": "text"
      },
      "source": [
        "### Introduction to Convolutional Neural Networks with TensorFlow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTO1h-GFKXMK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow==2.0.0-alpha0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3mGUhZwKgnw",
        "colab_type": "code",
        "outputId": "b004e68a-87e8-4720-efd7-e3d93a01e7aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#import print function from future\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "#import TensorFlow and check version\n",
        "import tensorflow as tf\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0.0-alpha0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hVXbCSRg37JC",
        "colab_type": "text"
      },
      "source": [
        "**MNIST Fashion Dataset**\n",
        "\n",
        "Downloading and feeding the dataset to the neural network is too simple. The dataset is conveniently included in the ketas module:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfVB3Nbs4Qpm",
        "colab_type": "code",
        "outputId": "23615d4b-f4ff-4d4c-c3fb-a4dc9f7f7bf6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhWjZJ4NNapx",
        "colab_type": "text"
      },
      "source": [
        "The image values are normalized by dividing them by 255.0, and therefore these values are cast to float numbers between 0.0 and 1.0."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVT35dpIl7_W",
        "colab_type": "text"
      },
      "source": [
        "**Building the Model for the Neural Network**\n",
        "\n",
        "So now we are going to train a small neural network. We'll use the MNIST dataset to train our network, and in this case we have a hidden layer of 128 neurons and an output layer of 10 neurons (MNIST: 1, 2, 3, 4, 5, 6, 7, 8, 9, 0 digits).\n",
        "\n",
        "Also, we are using Keras Flatten layer as the input layer. The MNIST dataset contains 28x28 images, we use the Flatten layer to turn those matrices into 784 (28x28) arrays. Now each hidden layer's neuron is connected to all 784 input layer's neurons."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdHZBskEpH9L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8f-Pwv6yUKR",
        "colab_type": "text"
      },
      "source": [
        "**Dropout Layer**\n",
        "\n",
        "One of the main issues faced by ML engineers is overfitting. According to Wikipedia, overfitting is \"the production of an analysis that corresponds too closely or exactly to a particular set of data, and may therefore fail to fit additional data or predict future observations reliably\".\n",
        "\n",
        "The process by which we prevent overfitting is called regularization.There are several methods for regularization; Dropout is a regularization technique that randomly drops out neurons during the training process.\n",
        "\n",
        "In this particular network, we added a Dropout layer between the hidden layer (128 neurons) and the output layer (10 neurons). It has a droput rate of 0.2, which means that each neuron in the hidden layer has a probability of 20% of being dropped out by the network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfCsmoODODu6",
        "colab_type": "text"
      },
      "source": [
        "**Training Configuration: Optimizer, Loss and Metrics**\n",
        "\n",
        "Now we need to choose the optimizer, the loss function and the metrics we are going to use to train our neural network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKPYSNl8Vew_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Os6LbSVTWB2F",
        "colab_type": "text"
      },
      "source": [
        "Then we train and evaluate our model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "siOIkFZCWH0_",
        "colab_type": "code",
        "outputId": "b605fd8c-ccef-46b0-9554-d30e44f22652",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "model.fit(x_train, y_train, epochs=5)\n",
        "\n",
        "model.evaluate(x_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 5s 91us/sample - loss: 0.0646 - accuracy: 0.9792\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 5s 91us/sample - loss: 0.0587 - accuracy: 0.9809\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 6s 95us/sample - loss: 0.0536 - accuracy: 0.9827\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 6s 98us/sample - loss: 0.0475 - accuracy: 0.9843\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 6s 97us/sample - loss: 0.0435 - accuracy: 0.9859\n",
            "10000/10000 [==============================] - 0s 45us/sample - loss: 0.0688 - accuracy: 0.9797\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.06875320029149298, 0.9797]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-bEiw4OmZBNT",
        "colab_type": "text"
      },
      "source": [
        "**Results**\n",
        "\n",
        "That's around 98% accuracy on the MNIST dataset. That's really outstanding for a NN with 3 layers (input, hidden and output). The droput is definitely an effective regularization technique."
      ]
    }
  ]
}