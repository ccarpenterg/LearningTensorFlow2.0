{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Gettingstarted_TensorFlow2_0_Pre-trained_Models.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ccarpenterg/LearningTensorFlow2.0/blob/master/05_pretrained_convnets_and_transfer_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdy7rZpLB8DB",
        "colab_type": "text"
      },
      "source": [
        "# Pretrained Convolutional Networks\n",
        "\n",
        "Before trying to tackle the problem of overfitting, we will explore the concept of a pre-trained convnet. So this is where the world of AI gets really exciting. We not only can use a great ML framework like TensorFlow, developed by Google, one the most advanced companies in terms of AI, but we also can download a pretrained convolutional neural network, that has been trained by a company like Google or by a research institution like Stanford.\n",
        "\n",
        "\n",
        "That means that years and years of research are **available** to everybody, provided they have the technical skillls to use these pretrained convolutional neural networks.\n",
        "\n",
        "Let's start by installing tensorflow 2.0 and checking we have the right version:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WchLDAhE97QO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow==2.0.0-beta1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9F5xKnx6Q9F",
        "colab_type": "code",
        "outputId": "355826ac-7ab7-4050-8e80-9e39d874689c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow\n",
        "\n",
        "print(tensorflow.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0.0-beta1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPn7ehNhwHcO",
        "colab_type": "text"
      },
      "source": [
        "## VGG16\n",
        "\n",
        "The VGG16 network was developed by the Visual Geometry Group at Oxford University, hence the name VGG. It has 16 layers, including convolutional and fullly connected layers, and a little more than 138 million parameters.\n",
        "\n",
        "We can download the convnet structure and parameters through the Keras module by instantiating the class VGG16:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYxCd1zEpvBy",
        "colab_type": "code",
        "outputId": "4c4cf201-6ab4-4c9c-87b8-8f078d130e93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 989
        }
      },
      "source": [
        "from tensorflow.keras.applications import VGG16\n",
        "\n",
        "convnet = VGG16()\n",
        "\n",
        "convnet.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
            "553467904/553467096 [==============================] - 40s 0us/step\n",
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 1000)              4097000   \n",
            "=================================================================\n",
            "Total params: 138,357,544\n",
            "Trainable params: 138,357,544\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBrDNJ3RZKbf",
        "colab_type": "text"
      },
      "source": [
        "So this is pretty much like downloading a brain, or a section a of a brain to be more precise. Now keep in mind that we have to re-train parts of a pretrained network so that we can apply the knowledge of this network to our particular problem.\n",
        "\n",
        "Most of the time the pretrained convnet has been trained on large datatasets such as Imagenet and with very different classes, so in order to apply it to our particular problem we will have to remove the dense classifier, which are the fully connected layers that sit on top of the convolutional and polling layers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJW7lm5nLq-s",
        "colab_type": "text"
      },
      "source": [
        "### Feature Extraction and Fine-tuning\n",
        "\n",
        "So why do we want to use a pre-trained convnet if its cassifier is not able to classify our images? The answer is **Feature extraction**. A convnet's architecture consists of two parts: the convolutional (and pooling) layers, and the classifier (fully connected layers).\n",
        "\n",
        "If we use the analogy of the human brain, we can say that the visual cortex is equivalent to our convolutional layers. They extract features like horizontal lines, vertical lines, curves, edges, etc.\n",
        "\n",
        "In the fundamental level, what the convnet is doing is extracting features like horizontal lines, vertical lines\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygXj3QmTDmbL",
        "colab_type": "code",
        "outputId": "0bcf7f54-763f-4f9a-b7ad-f3dcfa8a4456",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 853
        }
      },
      "source": [
        "from tensorflow.keras.applications import VGG16\n",
        "\n",
        "conv_base = VGG16(weights='imagenet',\n",
        "                  include_top=False,\n",
        "                  input_shape=(32, 32, 3))\n",
        "\n",
        "conv_base.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 7s 0us/step\n",
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 32, 32, 64)        36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 16, 16, 128)       73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 16, 16, 128)       147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 8, 8, 256)         295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 8, 8, 256)         590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 8, 8, 256)         590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 4, 4, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUqK4RL3U1qC",
        "colab_type": "text"
      },
      "source": [
        "### Freezing and Unfreezing Layers\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0_QlG86kmQe",
        "colab_type": "text"
      },
      "source": [
        "### Other Pretrained Convnets\n",
        "\n",
        "\n",
        "\n",
        "*   Xception\n",
        "*   ResNet\n",
        "*   Inception\n",
        "*   MobileNet\n",
        "*   DenseNet\n",
        "*   NASNet\n",
        "\n"
      ]
    }
  ]
}
