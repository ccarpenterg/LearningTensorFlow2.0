{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Gettingstarted-TensorFlow2.0.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ccarpenterg/LearningTensorFlow2.0/blob/master/01_getting_started_with_tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3Bkv9vJHsYg",
        "colab_type": "text"
      },
      "source": [
        "## Getting Started with Tensorflow 2: Training a NN on MNIST\n",
        "\n",
        "This is a small series of notebooks in which I introduce Tensorflow 2, which is the latest release of Google's machine learning framework. If you already know some Python you will be able to play with these examples, and even apply the same models to other datasets.\n",
        "\n",
        "If you're not familiar with Colab take a look at their [introductory notes](https://colab.research.google.com/notebooks/welcome.ipynb).\n",
        "\n",
        "### GPUs in Colab\n",
        "\n",
        "We'll be using the GPU that is provided by Google in Colab, so in order to enable the GPU for this notebook, follow the next steps:\n",
        "\n",
        "* Navigate to **Edit** â†’ **Notebook settings**\n",
        "* Open the **Hard accelerator** drop-down menu and select **GPU**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ns17SPcAmTL7",
        "colab_type": "text"
      },
      "source": [
        "## Image classification with Tensorflow\n",
        "\n",
        "Let's start by importing some standard functions, importing tensorflow, checking its version and how many GPUs are available if any:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3mGUhZwKgnw",
        "colab_type": "code",
        "outputId": "2c7b71bc-9395-4c30-fb24-b7fc0687979c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#import print function from future\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "%tensorflow_version 2.x\n",
        "#import TensorFlow and check version\n",
        "import tensorflow as tf\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n",
            "2.1.0-rc1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hVXbCSRg37JC",
        "colab_type": "text"
      },
      "source": [
        "### MNIST Dataset\n",
        "\n",
        "In this notebook we are going to work with the MNIST dataset. Basically it contains images of handwritten digits in grayscale, and its corresponding labels (one, two, three, etc).\n",
        "\n",
        "Downloading and feeding the dataset to the neural network is really simple. The dataset is conveniently included in the keras module:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfVB3Nbs4Qpm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhWjZJ4NNapx",
        "colab_type": "text"
      },
      "source": [
        "The image values are normalized by dividing them by 255.0, and therefore these values are cast to float numbers between 0.0 and 1.0."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpgTI-PGMGRO",
        "colab_type": "text"
      },
      "source": [
        "### Visualizing MNIST\n",
        "\n",
        "We take a look at our MNIST images. MNIST is the \"hello world!\"\" of neural networks, and it's a great dataset for getting started with a library like Tensorflow 2.0:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2e011HiiMVtx",
        "colab_type": "code",
        "outputId": "f9888e2e-4b18-4bcc-cbf2-b333d26c5a28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "for i in range(10):\n",
        "    plt.subplot(2, 5, i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(x_train[i], cmap=plt.cm.binary)\n",
        "plt.show()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAj8AAAEGCAYAAACKMfTPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 720x360 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVT35dpIl7_W",
        "colab_type": "text"
      },
      "source": [
        "### Building the Model for the Neural Network\n",
        "\n",
        "So now we are going to train a small neural network. We'll use the MNIST dataset to train our network, and in this case we have a hidden layer of 128 neurons and an output layer of 10 neurons (MNIST: 1, 2, 3, 4, 5, 6, 7, 8, 9, 0 digits).\n",
        "\n",
        "Also, we are using the Flatten layer as the input layer. The MNIST dataset contains 28x28 images, and we use the Flatten layer to turn those matrices into a 784 (28x28) elements array. Now each hidden layer's neuron is connected to all 784 input layer's neurons."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdHZBskEpH9L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olGBTbcqTuwa",
        "colab_type": "code",
        "outputId": "5efa2ef4-7900-4b99-b347-be02b1267501",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten (Flatten)            (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 101,770\n",
            "Trainable params: 101,770\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8f-Pwv6yUKR",
        "colab_type": "text"
      },
      "source": [
        "### Dropout Layer\n",
        "\n",
        "One of the main issues faced by ML engineers is overfitting. According to Wikipedia, overfitting is \"the production of an analysis that corresponds too closely or exactly to a particular set of data, and may therefore fail to fit additional data or predict future observations reliably\".\n",
        "\n",
        "The process by which we prevent overfitting is called regularization.There are several methods for regularization; Dropout is a regularization technique that randomly drops out neurons during the training process.\n",
        "\n",
        "In this particular network, we added a Dropout layer between the hidden layer (128 neurons) and the output layer (10 neurons). It has a droput rate of 0.2, which means that each neuron in the hidden layer has a probability of 20% of being dropped out by the network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfCsmoODODu6",
        "colab_type": "text"
      },
      "source": [
        "### Training Configuration: Optimizer, Loss and Metrics\n",
        "\n",
        "Now we need to choose the optimizer, the loss function and the metrics we are going to use to train our neural network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKPYSNl8Vew_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Os6LbSVTWB2F",
        "colab_type": "text"
      },
      "source": [
        "Then we train and evaluate our model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "siOIkFZCWH0_",
        "colab_type": "code",
        "outputId": "763d939f-9d80-40aa-f710-34e7c72674fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "model.fit(x_train, y_train, epochs=5)\n",
        "\n",
        "model.evaluate(x_test, y_test)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 6s 103us/sample - loss: 0.2921 - accuracy: 0.9157\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 4s 71us/sample - loss: 0.1430 - accuracy: 0.9573\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 4s 73us/sample - loss: 0.1067 - accuracy: 0.9678\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 4s 71us/sample - loss: 0.0894 - accuracy: 0.9721\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 4s 69us/sample - loss: 0.0757 - accuracy: 0.9759\n",
            "10000/10000 [==============================] - 1s 65us/sample - loss: 0.0790 - accuracy: 0.9764\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.07895432091394905, 0.9764]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-bEiw4OmZBNT",
        "colab_type": "text"
      },
      "source": [
        "### Results\n",
        "\n",
        "That's around 97% accuracy on the MNIST for both the training and test dataset. That's really outstanding for a NN with 3 layers (input, hidden and output). The droput is definitely an effective regularization technique."
      ]
    }
  ]
}